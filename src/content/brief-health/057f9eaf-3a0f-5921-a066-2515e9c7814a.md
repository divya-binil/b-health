---
aliases: /news/ai-bias-in-healthcare-discrimination-and-regulatory-uncertainty
archetype: curated-content
author:
  - Athira Ravi
basePath: /news/
breadcrumbLinks:
  - /
  - /news/
  - ''
breadcrumbs:
  - Home
  - News
  - 'AI Bias in Healthcare: Discrimination and Regulatory Uncertainty'
categories:
  - 'Healthcare IT News: Artificial Intelligence'
  - 'Medical Subject Headings (MeSH): Algorithms'
categorySlug:
  - 'healthcare it news: artificial intelligence'
  - 'medical subject headings (mesh): algorithms'
categoryUrl:
  - topic/healthcare-it-news-artificial-intelligence
  - topic/medical-subject-headings-mesh-algorithms
categoryLabel:
  - Artificial Intelligence
  - Algorithms
contentCategories: netspective-medigy-news-curated-content
institution: null
offering: null
layOut: single
date: '2022-06-10'
description: >-
  Ultimately, the discrimination is the result of the bias in the AI algorithm.

  HT: A recent survey suggested that over 36% of companies, not just in the
  healthcare industry, experienced challenges or d
favIconImage: null
featuredImage:
  alt: 'AI Bias in Healthcare: Discrimination and Regulatory Uncertainty'
  format: JPEG
  href: 057f9eaf-3a0f-5921-a066-2515e9c7814a-featuredImage.jpeg
  size:
    - 200
    - 344
  valid: true
  workPackage: 13515
  wpAttachment:
    fileName: Curated_Featured_Image.png
    link: /api/v3/attachments/24991/content
featuredPdf: null
htmlMetaData:
  author: null
  description: null
  generator: null
  viewport: null
  articlemodified_time: null
  articlepublished_time: null
  msvalidate.01: null
  ogdescription: >-
    More must be done to eliminate AI bias and discrimination so that healthcare
    companies can truly advance and embrace AI as a core function
  ogimage: null
  ogsite_name: null
  ogtitle: 'AI bias in healthcare: discrimination and regulatory uncertainty'
  ogtype: null
  ogupdated_time: null
  ogurl: null
  yandex-verification: null
  robots: null
  fbapp_id: null
  oglocale: null
  fbadmins: null
  articlepublisher: null
  google-site-verification: null
  keywords: null
id: 13515
identifier: News
lastMod: '2022-06-10T10:00:45.072299Z'
link:
  brand: healthcaretransformers.com
  href: 'https://healthcaretransformers.com/digital-health/ai-bias-in-healthcare/'
  original: 'https://healthcaretransformers.com/digital-health/ai-bias-in-healthcare/'
href: 'https://healthcaretransformers.com/digital-health/ai-bias-in-healthcare/'
original: 'https://healthcaretransformers.com/digital-health/ai-bias-in-healthcare/'
mastHead: NEWS
mdName: 057f9eaf-3a0f-5921-a066-2515e9c7814a.md
openGraphMetaData:
  ogdescription: >-
    More must be done to eliminate AI bias and discrimination so that healthcare
    companies can truly advance and embrace AI as a core function
  ogtitle: 'AI bias in healthcare: discrimination and regulatory uncertainty'
  ogurl: null
  ogimage: null
  ogsite_name: null
  ogtype: null
  ogupdated_time: null
  ogimageheight: null
openProjectCustomFields:
  cleanUrl: 'https://healthcaretransformers.com/digital-health/ai-bias-in-healthcare/'
  medigyTopics:
    - 'Healthcare IT News: Artificial Intelligence'
    - 'Medical Subject Headings (MeSH): Algorithms'
  sourceUrl: 'https://healthcaretransformers.com/digital-health/ai-bias-in-healthcare/'
openProjectWorkPackageType: Curated Content
searchCategory: News
slug: >-
  healthcaretransformers-ai-bias-in-healthcare-discrimination-and-regulatory-uncertainty
source: open-project-curations
status: ''
sub: brief
tags:
  - News
title: 'AI Bias in Healthcare: Discrimination and Regulatory Uncertainty'
via: ' '
insights_description: null
insights_name: null
viaLink: null
relatedOfferings:
  - label: nQ Cortex
    permalink: /offering/nq-cortex
    categories:
      - 'Medical Subject Headings (MeSH): Biomedical Technology'
      - 'Healthcare IT News: Artificial Intelligence'
    offeringId: 17453
  - label: Labviva Platform
    permalink: /offering/labviva-platform
    categories:
      - 'Healthcare IT News: Supply Chain'
      - 'Healthcare IT News: Artificial Intelligence'
    offeringId: 17330
  - label: Iktos Makya
    permalink: /offering/iktos-makya
    categories:
      - 'Healthcare IT News: Artificial Intelligence'
    offeringId: 17327
  - label: AI Dermatologist Platform
    permalink: /offering/ai-dermatologist-platform
    categories:
      - 'The Healthcare Guys: Skincare'
      - 'Healthcare IT News: Artificial Intelligence'
    offeringId: 17130
  - label: Armis Platform for Healthcare
    permalink: /offering/armis-platform-for-healthcare
    categories:
      - 'Healthcare IT News: Cybersecurity'
      - 'Healthcare IT News: Artificial Intelligence'
    offeringId: 16865
twitterMetaData:
  twittercard: null
  twitterdescription: >-
    More must be done to eliminate AI bias and discrimination so that healthcare
    companies can truly advance and embrace AI as a core function
  twittertitle: 'AI bias in healthcare: discrimination and regulatory uncertainty'
  twitterimage: null
  twitterurl: null
---
<p>Ultimately, the discrimination is the result of the bias in the AI algorithm.
HT: A recent survey suggested that over 36% of companies, not just in the healthcare industry, experienced challenges or direct business impact due to an occurrence of AI bias. Kay Firth-Butterfield: Bias comes into algorithms in several ways.
For example, if you’re building an algorithm with a world view and yet your developers are all young men in their twenties, when they’re thinking about what data to include and how to create the algorithm, they aren’t bringing that world view to it.
The other way that bias gets into algorithms is when you use the wrong data.
Kay Firth-Butterfield, AI in Healthcare_Balancing the business impacts of AI bias
HT: What are some direct business impacts due to AI bias in healthcare and other industries.
For example, if your algorithm is set up in the wrong way, then you are going to lose the opportunity of hiring people who will make your business succeed.
It has even been proven that if you employ an algorithm to predict the likelihood of someone recommitting a crime after being booked into jail, the data is so biased in the United States against people of color that even if the Black person was originally charged with a lesser offense than the White person, it will suggest that the Black person is more likely to recommit a crime.
</p><p>The other example comes from the Algorithmic Justice League – an organization that aims to raise public awareness about the impacts of AI – &nbsp;about how algorithms typically in the past have not identified Black women correctly.
Kay Firth-Butterfield, AI in healthcare_Women and diversity’s role in diminishing AI bias
Only 22% of women are AI scientists, which inevitably causes a bias and a problem with the way that the algorithms are going to be created. There is also a paucity of Black AI scientists.
The majority of people working in AI and creating algorithms are White males or Indian subcontinent males.
One of the ways that we’ve seen this being corrected is when you start to think about the algorithms that you’re going to use, bringing those diverse voices into the room.
For instance, due to the underrepresentation of women AI scientists, we’ve got to bring them in a different way, such as with your social scientists, which is great because often they bring that societal perspective that aids in the development of the algorithm anyway.</p><p>Evaluating AI algorithms
Kay Firth-Butterfield: There will be the European AI act, predicted to come into effect in 2024, but other than that there are little to no regulations as of today. There is some legislation in the US coming up around the use of algorithms in hiring because it is a huge impact on someone’s life.
As mentioned before the US Equal Employment Opportunity Commission (EEOC) is looking at algorithms based on the Civil Rights Act. The law exists to prevent discrimination against people by people and I think we will soon see cases brought by the EEOC against algorithms that discriminate against protected classes.
Once we see that happening, that will provide us with a baseline of how people and how companies are going to create and use algorithms.
If you’re a company producing that hiring algorithm and you sell it to another company that then has its workforce biased because you got it wrong, then you could be liable for the project that you created.</p>