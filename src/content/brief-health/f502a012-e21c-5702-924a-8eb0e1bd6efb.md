---
aliases: /news/the-pitfalls-of-ai-in-healthcare-bias-and-faulty-anonymisation
archetype: news
author:
- Admin
basePath: /news/
breadcrumbLinks:
- /
- /news
- https://healthmanagement.org/c/it/news/the-pitfalls-of-ai-in-healthcare-bias-and-faulty-anonymisation
- '#'
breadcrumbs:
- Home
- News
- healthmanagement.org
- 'The Pitfalls of AI in Healthcare: Bias and Faulty Anonymisation'
categories:
- ai
collection:
  name: news.healthcareguys.com
date: '2019-07-29T11:12:52Z'
featuredImage:
  format: JPEG
  href: f502a012-e21c-5702-924a-8eb0e1bd6efb-fi.jpeg
  mime_type: image/jpeg
  size:
  - 299
  - 300
imagePath: healthmanagement.org-the-pitfalls-of-ai-in-healthcare-bias-and-faulty-anonymisation
link:
  brand: healthmanagement.org
  href: https://healthmanagement.org/c/it/news/the-pitfalls-of-ai-in-healthcare-bias-and-faulty-anonymisation
  original: https://healthmanagement.org/c/it/news/the-pitfalls-of-ai-in-healthcare-bias-and-faulty-anonymisation
mastHead: NEWS
mdName: f502a012-e21c-5702-924a-8eb0e1bd6efb
searchCategory: News
slug: healthmanagement-the-pitfalls-of-ai-in-healthcare-bias-and-faulty-anonymisation
source: dropmark-curations
sub: brief
tags:
- News
title: 'The Pitfalls of AI in Healthcare: Bias and Faulty Anonymisation'
---

Artificial intelligence (AI) is increasingly used in healthcare, from improving the diagnosis of disease to making innovations in treatment. The role of AI in advancing precision medicine was the focus of a recent conference in Boston organised by Harvard Medical School. 

 

You might also like: AI in Medical Imaging May Make the Biggest Impact in Healthcare

 

The event featured a panel of experts that tackled the problems of applying AI in medicine and the many scientific, political, and ethical questions that must be addressed to ensure its safety and effectiveness. A panel member, Jonathan Zittrain, a Harvard Law School professor, expressed his apprehension that AI in healthcare could be the next asbestos.

 

“I think of machine learning kind of as asbestos,” Zittrain said. “It turns out that it’s all over the place, even though at no point did you explicitly install it, and it has possibly some latent bad effects that you might regret later, after it’s already too hard to get it all out.” He noted how AI can easily be duped into reaching false conclusions. To illustrate his point, he showed an image of a cat that a Google algorithm had correctly categorised as a tabby cat. The next slide contained a nearly identical picture of the cat, with only a few pixels changed, and this time Google classified the image as guacamole.

 

The discussions highlighted these key challenges related to the use of AI in medicine.